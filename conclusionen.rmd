---
output: html_document
---

SVMs tend to be *black boxes* (which means they are difficult to interpret) but they are very flexible. They automatically discover any relationship between inputs and the target, which means that you do not need to specify this relationship before modeling. 
<p>They can be used in several areas and as an alternative to other machine learning models.</p>
Unlike decision trees, a support vector is not something that most people can visualize.  The cost in calculation time is higher in calculation time than other methods.
<p>
As it is a detection fraud case, it is more likely to use *the loss function* to select our model.  
Nevertheless if we look at all our selections criterion *we can't really determine which one stands out from the others.*</p>

Three out of four models are in the same range of effectiveness, in this case, **the SVM is still competitive and procure us some good results.**


```{r, echo=FALSE}
library(htmltools)
htmltools::img(src = knitr::image_uri(file.path("www/logoESA.png")), 
               alt = 'logo', 
               style = 'position:absolute; bottom:1; right:0; padding:10px;width:2cm')
```